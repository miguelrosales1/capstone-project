{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFEC_EDADR</th>\n",
       "      <th>AFEC_EDUC</th>\n",
       "      <th>AFEC_GENERO</th>\n",
       "      <th>AFEC_GETNICO</th>\n",
       "      <th>AFEC_PARENTESCO</th>\n",
       "      <th>AFEC_POBESPECIAL</th>\n",
       "      <th>AFEC_REGAFILIACION</th>\n",
       "      <th>AFEC_TIPOPER</th>\n",
       "      <th>ALTO_COSTO</th>\n",
       "      <th>PATOLOGIA_1</th>\n",
       "      <th>PQR_CLASE_SNS</th>\n",
       "      <th>PQR_TIPOPETICION</th>\n",
       "      <th>COMPLETE_MOTIVE</th>\n",
       "      <th>RIESGO_VIDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827077</td>\n",
       "      <td>0.596597</td>\n",
       "      <td>0.527528</td>\n",
       "      <td>0.728729</td>\n",
       "      <td>0.856356</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.591592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804304</td>\n",
       "      <td>0.818819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866366</td>\n",
       "      <td>0.596597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728729</td>\n",
       "      <td>0.856356</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.591592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804304</td>\n",
       "      <td>0.649650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.830831</td>\n",
       "      <td>0.792292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728729</td>\n",
       "      <td>0.917918</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>0.575576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.591592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804304</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728729</td>\n",
       "      <td>0.910911</td>\n",
       "      <td>0.707207</td>\n",
       "      <td>0.575576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.591592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804304</td>\n",
       "      <td>0.573073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830831</td>\n",
       "      <td>0.596597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728729</td>\n",
       "      <td>0.910911</td>\n",
       "      <td>0.978979</td>\n",
       "      <td>0.575576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.962462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804304</td>\n",
       "      <td>0.845846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AFEC_EDADR  AFEC_EDUC  AFEC_GENERO  AFEC_GETNICO  AFEC_PARENTESCO  \\\n",
       "0  0.827077    0.596597   0.527528     0.728729      0.856356          \n",
       "1  0.866366    0.596597   1.000000     0.728729      0.856356          \n",
       "2  0.830831    0.792292   1.000000     0.728729      0.917918          \n",
       "3  0.830831    1.000000   1.000000     0.728729      0.910911          \n",
       "4  0.830831    0.596597   1.000000     0.728729      0.910911          \n",
       "\n",
       "   AFEC_POBESPECIAL  AFEC_REGAFILIACION  AFEC_TIPOPER    ALTO_COSTO  \\\n",
       "0  0.707207          1.000000            1.0           1.000000e-07   \n",
       "1  0.707207          1.000000            1.0           1.000000e-07   \n",
       "2  0.707207          0.575576            1.0           1.000000e-07   \n",
       "3  0.707207          0.575576            1.0           1.000000e-07   \n",
       "4  0.978979          0.575576            1.0           1.000000e-07   \n",
       "\n",
       "   PATOLOGIA_1  PQR_CLASE_SNS  PQR_TIPOPETICION  COMPLETE_MOTIVE  RIESGO_VIDA  \n",
       "0  0.591592     1.0            0.804304          0.818819         0            \n",
       "1  0.591592     1.0            0.804304          0.649650         0            \n",
       "2  0.591592     1.0            0.804304          0.777778         0            \n",
       "3  0.591592     1.0            0.804304          0.573073         0            \n",
       "4  0.962462     1.0            0.804304          0.845846         1            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "\n",
    "import model_utils as utils\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "dataset, features, labels = utils.getDataSet(\"datasets/dataset_best_features.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_final set has 2130783 samples.\n",
      "Training set has 1704626 samples.\n",
      "Testing set has 426157 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'labels' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    labels, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state = 10)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"features_final set has {} samples.\".format(features.shape[0])\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Training and Predicting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [F-score: 0.4395]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TP = np.sum(income) # Counting the ones as this is the naive case. Note that 'income' is the 'income_raw' data \n",
    "encoded to numerical values done in the data preprocessing step.\n",
    "FP = income.count() - TP # Specific to the naive case\n",
    "\n",
    "TN = 0 # No predicted negatives in the naive case\n",
    "FN = 0 # No predicted negatives in the naive case\n",
    "'''\n",
    "\n",
    "tp = float(np.sum(labels['RIESGO_VIDA']))\n",
    "fp = float(labels['RIESGO_VIDA'].count() - tp)\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "# TODO: Calculate accuracy, precision and recall\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "# HINT: The formula above can be written as (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "beta = 2\n",
    "fscore = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "\n",
    "# Print the results \n",
    "print \"Naive Predictor: [F-score: {:.4f}]\".format(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier trained on 1704626 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "model_utils.py:35: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier trained on 1704626 samples.\n",
      "AdaBoostClassifier trained on 1704626 samples.\n"
     ]
    }
   ],
   "source": [
    "import visuals as vs\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# Initialize the three models\n",
    "clf_A = SGDClassifier(random_state = 300)\n",
    "clf_B = RandomForestClassifier(random_state = 300)\n",
    "clf_C = AdaBoostClassifier(random_state = 300)\n",
    "\n",
    "\n",
    "samples_100 = len(y_train)\n",
    "samples_10 = int(samples_100*0.1)\n",
    "samples_1 = int(samples_10*0.1)\n",
    "\n",
    "# Collect results on the learners\n",
    "dfResults = pd.DataFrame(columns=['learner', 'learner_index', 'size_index', 'train_time', 'pred_time', 'f_test', 'f_train'])\n",
    "\n",
    "for k, clf in enumerate([clf_A, clf_B, clf_C]):\n",
    "    clf_name = clf.__class__.__name__    \n",
    "    dfResults = utils.train_predict(clf, k, 0, samples_100, X_train, y_train, X_test, y_test, dfResults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learner</th>\n",
       "      <th>f_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.524142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.462051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.239492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  learner    f_test\n",
       "1  RandomForestClassifier  0.524142\n",
       "2  AdaBoostClassifier      0.462051\n",
       "0  SGDClassifier           0.239492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( dfResults.sort_values(by=['f_test'], ascending = False)[['learner', 'f_test']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "F-score on testing data: 0.5229\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final F-score on the testing data: 0.7078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rfClassifier.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "rfClassifier = RandomForestClassifier(random_state = 20)\n",
    "\n",
    "rfParameters = {    \n",
    "  'criterion':['gini', 'entropy'],\n",
    "  'max_depth':[5, 10],\n",
    "  'max_features':['auto', 'sqrt', 'log2', None],\n",
    "  'class_weight': ['balanced', 'balanced_subsample'], \n",
    "}\n",
    "\n",
    "rfClassifier = utils.tuneClassifier(rfClassifier, rfParameters, X_train, X_test, y_train, y_test)\n",
    "\n",
    "joblib.dump(rfClassifier, 'rfClassifier.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "F-score on testing data: 0.4621\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final F-score on the testing data: 0.4621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaClassifier = AdaBoostClassifier(random_state = 20)\n",
    "\n",
    "adaParameters = {\n",
    "  'learning_rate':[0.1, 0.5, 1],\n",
    "  'algorithm' :['SAMME', 'SAMME.R']\n",
    "  #'max_features':['auto', 'sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "adaParameters = utils.tuneClassifier(adaClassifier, adaParameters, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score on StackingClassifier: 0.6767\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "#meta with Gaussian\n",
    "sclf = StackingClassifier(classifiers=[rfClassifier, adaClassifier], \n",
    "                          use_features_in_secondary = True,\n",
    "                          meta_classifier=GaussianNB())\n",
    "sclf = sclf.fit(X_train, y_train)\n",
    "sclf_predictions = sclf.predict(X_test)\n",
    "\n",
    "print \"F-score on StackingClassifier: {:.4f}\".format(fbeta_score(y_test, sclf_predictions, beta = 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
